{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Creation  df  au cas ou "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df')\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = df[:1017100]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "f = int(len(df)/10)\n",
    "f\n",
    "for x in range(10):    \n",
    "    dfx = df[x*f : (x+1)*f]\n",
    "    x*f , (x+1)*f , dfx.shape\n",
    "    dfx.to_csv('valeursfoncieres-2019_{}.csv'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur le site de data gouv : https://www.data.gouv.fr/fr/datasets/demandes-de-valeurs-foncieres-geolocalisees/\n",
    "On récupère plusieurs fichiers correspondants à différentes. Dans cette section on présente une routine pour stocker les chemins d’acces de ces fichiers et les stocker dans une liste grâce à l’utils glob. Cette démarche est similaire une request par exemple.\n",
    "\n",
    "1. Glob permet de créer une liste python des fichiers .txt stockés dans le dossier data.\n",
    "1. On charge le premier élément de la liste dans un dataframe  grâce à l’option read_csv. \n",
    "1. Il est important après avoir chargé des données de vérifier son shape (nombre de ligne / colonne) avec la commande du même nom mais également de print un échantillon, ici les 10 premières lignes avec la commande head équivalent a .loc[ :10]. \n",
    "1. On note la présence de valeur null, donc non renseigné mais également de nombreuses colonnes dont seulement une partie seront utile par la suite.\n",
    "1. Pour chaque section on sauvegarde le dataframe dans le format le plus efficace pour des df pandas : pickle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import glob, os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#permet d'afficher des graph dans le notebook\n",
    "%matplotlib inline \n",
    "\n",
    "#permet d'afficher plusieurs sortis par cellule sans utiliser print()\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#permet d'augemnter la largeur des cellules\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70%! important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optionnel si difficulté pour autocompletion \n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load [exo]\n",
    "    charger un dataframe a partir de plusieurs csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path = 'Data2\\valeursfoncieres-2019_0.csv'\n",
    "'exemple_{}'.format(1)\n",
    "pd.read_csv(path)\n",
    "ListDataframe = []\n",
    "df = pd.concat([listdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filelist = ['Data2\\\\valeursfoncieres-2019_{}.csv'.format(x) for x in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Data2\\*.csv'\n",
    "Filelist = glob.glob(path)\n",
    "Filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listdf = [pd.read_csv(f) for f in Filelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df  = pd.concat(listdf)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nettoyage data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est fréquent de vérifier le format des données en particulier si une colonne contient différents types (ex int , str ….), il convient de systématiquement corriger le format des données pour pouvoir les analyser avec pandas.\n",
    "1. On présente ici une méthode rapide à mettre en œuvre pour établir un état des lieux de notre dataframe. La fonction apply de pandas permet d’appliquer une fonction à toutes les valeurs d’une colonne dans ce cas  la fonction python type. On note que 2 colonnes sont concernées par des types différents Valeur_fonciere & Code_departement (str & int).  \n",
    "1. Commençons par Valeur_fonciere, on réalise un masque des données de type str. Ces valeurs procèdent en plus une virgule, il faut le corriger. Nous appliquons un split sur ces valeurs en sélectionnant la partie à gauche de la virgule et assignons ces valeurs dans le dataframe, désormais nous pouvons sans risque utiliser la fonction pandas to_numeric pour passer du type str a float. \n",
    "1. Pour le Code_departement, un problème diffèrent se pose, comme on peut le voir en réalisant un print des valeurs uniques. Les codes département de la corse sont 2A et 2B, il faut donc conservé les valeurs sous un format str, de plus sur les valeurs inferieurs a 10 il faut rajouter le 0 ex 1 = 01.\n",
    "1. La première étape est de passer toutes les valeurs en str avec la fonction astype (str) \n",
    "1. Ensuite réaliser un masque sur les valeurs de code inferieur à 10, donc avec seulement un chiffre, ici la fonction apply len renvoi le nombre de caractère pour chaque valeur, il suffit ensuite de faire un slice des données avec un mask len = 1  et d’ajouter le 0.\n",
    "1. Dans le cas de la colonne de date pandas réalise cette opération avec la fonction to_datetime (attention toute fois au format des données d’entrée) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## astuce print"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".apply(type)\n",
    ".value_counts()\n",
    "pd.DataFrame([**** for c in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Valeur_fonciere.apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dftype = pd.DataFrame([df[c].apply(type).value_counts() for c in df.columns])\n",
    "dftype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftype[dftype.isnull().sum(1) !=2]\n",
    "dftype[dftype.isnull().sum(1) !=2].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valeur_fonciere [exo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Valeur_fonciere.apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".apply(type) == str\n",
    ".str.split(',')\n",
    ".str[0]\n",
    "mask\n",
    "pd.to_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(list(range(7)), index= list('ABCDEFG'))\n",
    "mask = s>3\n",
    "s[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(list('0123456'), index= list('ABCDEFG'))\n",
    "s.values\n",
    "pd.to_numeric(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df.Valeur_fonciere.apply(type) == str\n",
    "df.Valeur_fonciere[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val = df.Valeur_fonciere[mask].str.split(',').str[0]\n",
    "new_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[mask, 'Valeur_fonciere'] = new_val\n",
    "df.Valeur_fonciere = pd.to_numeric(df.Valeur_fonciere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Valeur_fonciere.apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code_departement [exo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Code_departement.apply(type).value_counts()\n",
    "df.Code_departement.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Code_departement = df.Code_departement.astype(str) \n",
    "df.Code_departement.unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".astype(str) \n",
    ".apply(len) \"optionnel\"\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Code_departement = df.Code_departement.astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Len = df.Code_departement.apply(len)\n",
    "Len.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = Len == 1\n",
    "df.loc[mask, 'Code_departement']= '0' + df.loc[mask, 'Code_departement']\n",
    "df.Code_departement.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Code_departement.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date_mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Date_mutation = pd.to_datetime(df.Date_mutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrichissement : region  [exo]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’enrichissement permet d’ajouter au dafaframe des colonnes de données utiles mais non présent dans le jeu de base. Ici nous allons rajouter les régions\n",
    "1. la csv des donnés est dans le lien suivant : https://www.data.gouv.fr/fr/datasets/regions-departements-villes-et-villages-de-france-et-doutre-mer/\n",
    "1. On charge ces données dans un nouveau dataframe dfgeo et ainsi refaire les étapes de nettoyage des données avant de le combiner avec df.\n",
    "1. Apres comptage il n’y a que 100 dep dans ce fichier et en comparant les code_departement dans les deux fichiers il manque le dep 75, on peut le rajouter avec un dict en entrée.\n",
    "1. Enfin on ajoute les colonnes région et code_region dans df avant de sauvegarder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Code_departement.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgeo = pd.read_csv('data/departements-france.csv')\n",
    "dfgeo\n",
    "dfgeo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verification nombre de departement\n",
    "dfgeo.code_departement.nunique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".set_index()\n",
    ".map()\n",
    "df['Region'] = \n",
    "df['code_region'] ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ex map\n",
    "s = pd.Series(['a','b','c'])\n",
    "d ={'a' : 0,\n",
    "    'b' : 1,\n",
    "    'c' : 2}\n",
    "s.map(d)\n",
    "s.map(pd.Series(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Code_departement.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~df.Code_departement.isin(dfgeo.code_departement)].Code_departement.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "dfgeo.loc[dfgeo.shape[0]] = ['75', 'Paris', '11', 'Île-de-France']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgeo[dfgeo.nom_region == 'Île-de-France']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgeo.code_departement.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Region'] = df.Code_departement.map(dfgeo.set_index('code_departement')['nom_region'])\n",
    "df['code_region'] = df.Code_departement.map(dfgeo.set_index('code_departement')['code_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# json export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#PL un des points importants: la création/génération (et également l'utilisation de fait) de format .json.\n",
    "\n",
    "params = ['split', 'records', 'index', 'columns', 'values', 'table']\n",
    "\n",
    "for param in params:\n",
    "    print (param)\n",
    "    print (df.iloc[:5,:5].to_json(orient=param))\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Test export json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "https://app.rawgraphs.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "###rawgraphs (~Maxx) Optionnel\n",
    "\n",
    "data.index.name = 'index'\n",
    "\n",
    "data[:1000].fillna(0).astype(int).to_clipboard(sep=',')\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "885.3px",
    "left": "76px",
    "top": "32.6833px",
    "width": "408.767px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
