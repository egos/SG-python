{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dans cette partie nous abordons concrètement les fonctionnalité de pandas pour l’analyse de données. \n",
    "* Notamment nous aborderons les  opérateurs usuelles (average min , max , quantile ) , les fonction de transformation pivot et groupby , stack/unstack et sur les time series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# import   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import glob, os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#permet d'afficher des graph dans le notebook\n",
    "%matplotlib inline \n",
    "\n",
    "#permet d'afficher plusieurs sortis par cellule sans utiliser print()\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#permet d'augemnter la largeur des cellules\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70%! important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#optionnel si difficulté pour autocompletion \n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df')\n",
    "df.shape\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Fonction descriptive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nous avons déjà rencontré dans la section manipulation les fonctions  values_counts et nunique. Ici nous présentons la fonction describe qui donne de nombreuses informations condensées sur le dataframe (min max , count , quantile …)\n",
    "1. Le résultat de describe est un dataframe qui peut donc être manipulé ainsi par ex nous pouvons faciliter l’affichage en appliquant les fonctions round ou astype ( int ) \n",
    "1. Par défaut cette fonction ne prend que les valeurs numériques mais nous pouvons modifier cette sélection avec l’option  include / exclude . On note dans ce cas  l’apparition de nouvelles métriques en index (top , freq …) . \n",
    "1. Il est important de noter que les métriques affichées dans describe sont accessibles directement via des fonctions pandas (min max par ex) mais également le quantile 75% correspond à la fonction quantile a 0.75. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.Date_mutation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.describe().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.describe(exclude = [np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.Valeur_fonciere.describe()['75%']\n",
    "df.Valeur_fonciere.quantile(0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Cette fonction, que l’on retrouve littéralement dans le langage SQL , est utiliser pour grouper les données autour d’une fonction d’agrégation. Elle implique plusieurs opérations pour fonctionner selon la logique split-apply-combine. On suppose ici que les formés sont déjà habitué au concept de groupby.\n",
    "1. Il faut déterminer la clef de groupe ici région ce qui génère un objet groupby, qui peut être réutiliser ensuite.\n",
    "1. Sur cet objet on applique une ou plusieurs listes de valeurs et une fonction d’agrégation : ici la moyenne, le résultat obtenu est une nouvelle série si le groupby est réalisé sur 1 seule colonne. \n",
    "1. La plupart des fonctions pandas sont accessible comme méthode d’agrégation comme par exemple describe. \n",
    "1. Dans le cas où on a besoin de réaliser une opération spécifique par colonnes on peut aussi utiliser la commande agg et pour les groupes de donnés la fonction apply ou map.\n",
    "1. La clef de groupe peut également être un masque sur les données : ex ici on catégorise les surfaces de terrain supérieur ou inferieur a 100 m2. En python la fonction lambda permet d’utiliser des opérateurs sur chaque donnée x.\n",
    "1. Astuce : dans le cas de plusieurs clefs de group on peut les renseigner soit avec leur nom ou directement en avec une série de valeur , il faut veiller à ce que les tailles des tableaux correspondent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.groupby('Region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.groupby('Region')['Valeur_fonciere'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.groupby('Region')['Valeur_fonciere'].mean().astype(int).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.groupby('Region')['Valeur_fonciere'].describe().astype(int).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Surface_terrain  > 100\n",
    "df.groupby((df.Surface_terrain  > 100))['Valeur_fonciere'].mean().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mask = (df.Surface_terrain  > 100).map({False : '< 100', True : '> 100'})\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.groupby(mask)['Valeur_fonciere'].mean().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#rappel base python = des listes partout\n",
    "df.groupby(['Region', df.Code_departement , mask])['Valeur_fonciere'].mean().astype(int).to_frame().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['Region'])['Valeur_fonciere'].apply(lambda x : 'good' if np.mean(x)< 300000 else 'bad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* Il existe différentes méthodes pour effectuer un reshape d’un dataframe (ex inverser ligne colonne). Rappelons que pandas comme python permet d’aboutir au même résultat avec des fonctions différentes. \n",
    "* L’objectif de cette section n’est pas d’être exhaustif mais plutôt de montrer quelle sont les bonnes pratiques en la matière et les pièges à éviter. Pour cela nous allons nous servir des similitudes entre groupby et pivot. \n",
    "* On conseil au formé de suivre ce lien au besoin qui illustre bien ces mécanismes : https://pandas.pydata.org/docs/user_guide/reshaping.html\n",
    "* Dans cette section nous utiliserons une colonne catégorielle des surfaces avec la fonction cut, on commence par l’ajouter à df. En effet il est plus judicieux de comparer des surfaces de même ordre de grandeur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df')\n",
    "df.shape\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "df.Valeur_fonciere = df.Valeur_fonciere.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.cut(df.Surface_reelle_bati, bins= [0,10,100,10000,100000]).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = pd.cut(df.Surface_reelle_bati, bins= [0,10,100,1000])\n",
    "df.groupby([df.code_region, a]).size().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['Surface_Categorie'] = pd.cut(df.Surface_reelle_bati.fillna(0), bins= [-1,0,10,100,10000,100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['Region', df.Surface_Categorie]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Il est très important lorsque on applique un reshape sur un dataframe de vérifier que les colonnes utilisées respectent une forme d’unicité des valeurs. \n",
    "1. Ce point est illustré avec la fonction pivot qui est la plus condensée pour du reshaping. Si on essaye de faire un pivot sur df region et categorie de surface cela génère une erreur : Index contains duplicate entries, cannot reshape.\n",
    "1. Un moyen simple pour reshape ce type de dataframe et unifier les valeurs, est d’utiliser un groupby. Notons que nous pouvons arriver au même résultat en utilisant la fonction avancée de pivot = pivot table avec une fonction d’agrégation. La fonction stack sera expliqué dans la section suivante. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.pivot(index = 'Region',columns= 'Surface_Categorie' , values= 'Valeur_fonciere')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['Region', df.Surface_Categorie]).Valeur_fonciere.mean().fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.pivot_table(index = 'Region', columns = df.Surface_Categorie, values='Valeur_fonciere', aggfunc=np.mean).stack()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "RESULTAT\n",
    "Region                Surface_Categorie\n",
    "Auvergne-Rhône-Alpes  (-1, 0]              5.843833e+05\n",
    "                      (0, 10]              1.903047e+06\n",
    "                      (10, 100]            6.574020e+05\n",
    "                      (100, 10000]         5.180871e+05\n",
    "                      (10000, 100000]      8.745354e+05\n",
    "                                               ...     \n",
    "Île-de-France         (-1, 0]              1.073631e+06\n",
    "                      (0, 10]              4.723261e+06\n",
    "                      (10, 100]            3.239693e+06\n",
    "                      (100, 10000]         1.975397e+06\n",
    "                      (10000, 100000]      2.835465e+07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## multi index & stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Dans la suite nous travaillons avec le dataframe groupé df2 (mean des valeurs foncières). Il est important de noter que df2 possède un multi index ce que nous pouvons vérifier avec df2.index. Le multi index est composé de level d’index.\n",
    "1. Pour retrouver un df avec un unique level d’index il faut utiliser la commande reset_index, l’opération inverse se fait avec  set_index (colonnes) .\n",
    "1. La caractéristique de pivot table et de basculer un level d’index en colonne cela peut être réalisé sur le dataframe multi-index df2  avec la commande unstack (En argument nous pouvons décider quel level d’index sera passé en colonne de la même façon que l’argument columns dans pivot table). L’opération inverse se fait avec stack\n",
    "1. En conclusion groupby + unstack est équivalent à pivot table. L’intérêt en mode notebook de travailler avec ce type de shape est qu’il est facile de faire un graphique comme on peut le voir dans cet exemple ou on calcule le pourcentage de valeur foncière. \n",
    "1. A titre d’exemple nous réalisons la même opération avec le dénombrement des habitations par surface et par région.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Region', df.Surface_Categorie]).Valeur_fonciere.mean().fillna(0).astype(int)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2.index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2.reset_index().Surface_Categorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2.reset_index().set_index(['Region', 'Surface_Categorie']).Valeur_fonciere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2.unstack().stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['Region', df.Surface_Categorie]).Valeur_fonciere.mean().fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['Region', df.Surface_Categorie]).Valeur_fonciere.mean().fillna(0).astype(int).unstack().plot.barh(stacked = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2 = df.pivot_table(index = 'Region', columns = df.Surface_Categorie, values='Valeur_fonciere', aggfunc=np.mean)\n",
    "df2\n",
    "(100*df2.div(df2.sum(1), 0)).plot.barh(stacked = True)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['Region', df.Surface_Categorie]).size().unstack().plot.barh(stacked = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Region', df.Surface_Categorie]).size().unstack()\n",
    "(100*df2.div(df2.sum(1), 0)).plot.barh(stacked = True, cmap = 'autumn')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# TimeSerie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Les times series sont des particularités dans le traitement de données qui nécessite des fonctions spécifiques. On retrouve comme première étape celle de s’assurer que les données sont bien au format de donnée date-time (si besoin on utilise la fonction de pandas to_datetime vue plus avant).\n",
    "1. Les formats datetime sont manipulables avec pandas par l’intermédiaire de la fonction dt qui permet  par exemple de sélectionner un range de date spécifique ici month. \n",
    "1. La colonne date est traité vis-à-vis de pandas de la même façon que toute autre type de colonne  ex value count et groupby. \n",
    "1. Il est souvent utile de travailler sur des range de date sur mesure la moyenne roulante est déjà bien connu dans le milieu bancaire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## to Date time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.Date_mutation.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['Date_mutation'] = pd.to_datetime(df['Date_mutation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Manip dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.Date_mutation.dt.month.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(df.Date_mutation.dt.month)\n",
    "grouped.Valeur_fonciere.sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby([df.Region, df.Date_mutation.dt.month])\n",
    "grouped.Valeur_fonciere.sum().unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby([df.Region, df.Date_mutation.dt.month])\n",
    "grouped.Valeur_fonciere.sum().unstack(0).cumsum().plot(figsize = (20,5) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# rolling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfparis = df[df.Region == 'Île-de-France']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfparis.set_index('Date_mutation').Valeur_fonciere.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = dfparis.set_index('Date_mutation').sort_index()\n",
    "a.Valeur_fonciere.rolling('7d').sum().plot()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "885.3px",
    "left": "76px",
    "top": "32.6833px",
    "width": "408.767px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
